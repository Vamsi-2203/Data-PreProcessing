{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87bdbef7-eab1-4ba1-aa09-a19e82166c9f",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdcbd6-f7af-4247-bf16-b8a2e67ced77",
   "metadata": {},
   "source": [
    "- Data cleaning is the process of identifying and correcting (or removing) inaccurate, incomplete, or irrelevant data to improve its quality and ensure that machine learning models are trained effectively.\n",
    "- Poor data quality can lead to incorrect or biased results, making data cleaning an essential step in the preprocessing pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35334638-4efe-4f48-8d33-08f29695fada",
   "metadata": {},
   "source": [
    "#### Common Data Cleaning Techniques\n",
    "##### 1. Handling Missing Data\n",
    "- Missing data is a common issue in datasets. Common techniques include:\n",
    "\n",
    "##### Removal of Missing Data\n",
    "\n",
    "- Remove rows or columns with missing values.\n",
    "- Suitable when the missing data is a small percentage of the dataset.\n",
    "##### Imputation\n",
    "\n",
    "###### Replace missing values with:\n",
    "- Mean/Median/Mode: For numerical or categorical data.\n",
    "- Forward/Backward Fill: Use adjacent values for time-series data.\n",
    "- Predictive Models: Use regression or k-nearest neighbors (KNN) to predict missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e60a6-7595-4f75-b69c-7944c606d0e7",
   "metadata": {},
   "source": [
    "## 2. Handling Duplicates\n",
    "- Duplicate records can distort analysis and model training.\n",
    "\n",
    "- Detection: Use functions like pandas.DataFrame.duplicated() in Python.\n",
    "- Removal: Drop duplicate rows using tools like drop_duplicates() in Python or manual filtering in spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ecc74-ea87-440f-a261-5d87b6aa24ea",
   "metadata": {},
   "source": [
    "## 3. Outlier Detection and Removal\n",
    "- Outliers can skew analysis and model performance.\n",
    "\n",
    "#### Statistical Methods:\n",
    "- Remove data points outside a specified range (e.g., ±3 standard deviations or outside the IQR).\n",
    "- Use Z-scores or boxplots to identify anomalies.\n",
    "#### Domain Knowledge: \n",
    "- Apply context-specific thresholds to identify invalid values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a853796-79d6-4909-baba-59410d26352b",
   "metadata": {},
   "source": [
    "## 4. Standardizing Data Formats\n",
    "- Ensure consistency in data formats to avoid processing errors.\n",
    "\n",
    "- Date Formats: Convert all date-time fields into a standard format (e.g., ISO 8601).\n",
    "- String Formats: Standardize case (e.g., all lowercase), remove trailing spaces, or unify abbreviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212d48a1-a224-4e13-ac70-735ce72499f8",
   "metadata": {},
   "source": [
    "## 5. Removing Irrelevant Data\n",
    "- Identify and remove columns or rows that are unnecessary or redundant for the analysis.\n",
    "\n",
    "#### Feature Selection: \n",
    "- Use techniques like correlation analysis or feature importance scores to decide which features to retain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b126b42-4689-490d-aedc-b452d9c30ab0",
   "metadata": {},
   "source": [
    "## 6. Fixing Data Entry Errors\n",
    "- Correct typographical or logical errors in the data.\n",
    "\n",
    "- Regex Matching: Identify and fix patterns that don’t conform (e.g., email formats, phone numbers).\n",
    "- Manual Review: For small datasets, inspect and correct errors manually.\n",
    "- Automated Scripts: Write custom scripts to clean recurring issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52e4fe-19b9-4ede-9311-bc7647e2cd94",
   "metadata": {},
   "source": [
    "## 7. Consistent Encoding\n",
    "- Ensure categorical variables have consistent values.\n",
    "\n",
    "- Example: Replace variations like \"Male,\" \"M,\" and \"male\" with a single representation (\"Male\").\n",
    "- Tools: Use Python's replace() or map() functions for mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1db80-e103-4f93-a675-efddf32a0744",
   "metadata": {},
   "source": [
    "## 8. Handling Out-of-Range Values\n",
    "- Detect values that fall outside an acceptable domain.\n",
    "\n",
    "- Example: If \"age\" has values above 120 or below 0, flag them as errors.\n",
    "- Actions: Replace out-of-range values with appropriate substitutes or remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31915c9-bb96-46a6-a7b4-19495b330b53",
   "metadata": {},
   "source": [
    "## 9. Converting Data Types\n",
    "- Incorrect data types can lead to errors during analysis.\n",
    "\n",
    "- Example: Convert numerical strings (e.g., \"100\") to integers.\n",
    "- Tools: Use functions like astype() in Python or type conversion methods in SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31067205-5310-4fe2-bd22-ad3c1cd7482d",
   "metadata": {},
   "source": [
    "## 10. Resolving Data Inconsistencies\n",
    "- Case Sensitivity: Ensure consistent casing in text data (e.g., \"Apple\" vs. \"apple\").\n",
    "- Unifying Units: Convert units to a common scale (e.g., inches to centimeters).\n",
    "- Duplicate Categories: Merge similar categories (e.g., \"NY\" and \"New York\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acd701-ec57-4e52-8384-cbf4b5e91ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48895dd-e7dc-4d02-8a43-a154bb0e0eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age City  Age_mean  Age_median City_mode\n",
      "0  25.0   NY      25.0        25.0        NY\n",
      "1  30.0   LA      30.0        30.0        LA\n",
      "2   NaN  NaN      32.5        32.5        LA\n",
      "3  35.0   NY      35.0        35.0        NY\n",
      "4  40.0   LA      40.0        40.0        LA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Age': [25, 30, np.nan, 35, 40], 'City': ['NY', 'LA', np.nan, 'NY', 'LA']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mean Imputation for 'Age'\n",
    "df['Age_mean'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Median Imputation for 'Age'\n",
    "df['Age_median'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Mode Imputation for 'City'\n",
    "df['City_mode'] = df['City'].fillna(df['City'].mode()[0])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3294ded-79a9-4dd5-96e0-d57016298669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant Imputation\n",
    "# Fills missing values with a constant value (e.g., 0, \"Unknown\").\n",
    "\n",
    "#Use case: When domain knowledge suggests a default value.\n",
    "\n",
    "df['City_constant'] = df['City'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53159c1b-ca35-46cf-aadb-425a73e21896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Forward Fill and Backward Fill\n",
    "# Use adjacent values in time-series or ordered data.\n",
    "# Forward Fill: Propagate the last observed value forward.\n",
    "# Backward Fill: Use the next observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9731d0-93a8-4d1f-968f-527c64fbd76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age City  Age_mean  Age_median City_mode  Age_ffill  Age_bfill\n",
      "0  25.0   NY      25.0        25.0        NY       25.0       25.0\n",
      "1  30.0   LA      30.0        30.0        LA       30.0       30.0\n",
      "2   NaN  NaN      32.5        32.5        LA       30.0       35.0\n",
      "3  35.0   NY      35.0        35.0        NY       35.0       35.0\n",
      "4  40.0   LA      40.0        40.0        LA       40.0       40.0\n"
     ]
    }
   ],
   "source": [
    "# Forward Fill\n",
    "df['Age_ffill'] = df['Age'].fillna(method='ffill')\n",
    "\n",
    "# Backward Fill\n",
    "df['Age_bfill'] = df['Age'].fillna(method='bfill')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb481a9f-f853-46f4-9597-6b1c22f1bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age City  Age_mean  Age_median City_mode  Age_ffill  Age_bfill  Age_interp\n",
      "0  25.0   NY      25.0        25.0        NY       25.0       25.0        25.0\n",
      "1  30.0   LA      30.0        30.0        LA       30.0       30.0        30.0\n",
      "2   NaN  NaN      32.5        32.5        LA       30.0       35.0        32.5\n",
      "3  35.0   NY      35.0        35.0        NY       35.0       35.0        35.0\n",
      "4  40.0   LA      40.0        40.0        LA       40.0       40.0        40.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Interpolation\n",
    "# Estimate missing values by interpolating between available data points. Works well for numerical data.\n",
    "\n",
    "# Interpolation\n",
    "df['Age_interp'] = df['Age'].interpolate(method='linear')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5aa5d5-dff0-4f71-a1ad-51b3adb6f7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2\n",
      "0       1.0       7.0\n",
      "1       2.0       8.5\n",
      "2       2.5       9.0\n",
      "3       4.0      10.0\n"
     ]
    }
   ],
   "source": [
    "# 4. K-Nearest Neighbors (KNN) Imputation\n",
    "# Replace missing values based on the values of the k-nearest neighbors.\n",
    "# Uses features of nearby rows to infer missing values.\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Sample DataFrame\n",
    "data_knn = {'Feature1': [1, 2, np.nan, 4], 'Feature2': [7, np.nan, 9, 10]}\n",
    "df_knn = pd.DataFrame(data_knn)\n",
    "\n",
    "# KNN Imputation\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_knn_imputed = pd.DataFrame(imputer.fit_transform(df_knn), columns=df_knn.columns)\n",
    "\n",
    "print(df_knn_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6918955-9505-4686-9fec-a4e046e3184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Salary\n",
      "0  25.0   50000\n",
      "1  30.0   60000\n",
      "2  32.5   70000\n",
      "3  35.0   80000\n",
      "4  40.0   90000\n"
     ]
    }
   ],
   "source": [
    "# 5. Regression Imputation\n",
    "# Use regression models to predict and replace missing values.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample DataFrame\n",
    "data_reg = {'Age': [25, 30, np.nan, 35, 40], 'Salary': [50000, 60000, 70000, 80000, 90000]}\n",
    "df_reg = pd.DataFrame(data_reg)\n",
    "\n",
    "# Split into known and unknown\n",
    "known = df_reg[df_reg['Age'].notnull()]\n",
    "unknown = df_reg[df_reg['Age'].isnull()]\n",
    "\n",
    "# Train regression model\n",
    "model = LinearRegression()\n",
    "model.fit(known[['Salary']], known['Age'])\n",
    "\n",
    "# Predict missing values\n",
    "df_reg.loc[df_reg['Age'].isnull(), 'Age'] = model.predict(unknown[['Salary']])\n",
    "\n",
    "print(df_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6966dac7-db2a-4f3b-99fd-34f8e6acbd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Salary\n",
      "0  25.0   50000\n",
      "1  35.0   60000\n",
      "2  35.0   70000\n",
      "3  35.0   80000\n",
      "4  40.0   90000\n"
     ]
    }
   ],
   "source": [
    "# 6. Multiple Imputation\n",
    "# Perform multiple imputations to create multiple datasets with plausible values and combine the results for robustness.\n",
    "# Example:\n",
    "\n",
    "# This typically requires a library like statsmodels or fancyimpute. Here's a simple demonstration using statsmodels.\n",
    "\n",
    "from statsmodels.imputation.mice import MICEData\n",
    "\n",
    "# Sample DataFrame\n",
    "data_mice = {'Age': [25, np.nan, 35, np.nan, 40], 'Salary': [50000, 60000, 70000, 80000, 90000]}\n",
    "df_mice = pd.DataFrame(data_mice)\n",
    "\n",
    "# Multiple Imputation\n",
    "mice_data = MICEData(df_mice)\n",
    "df_mice_imputed = mice_data.data\n",
    "\n",
    "print(df_mice_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9a74cb-e6ca-4188-8d05-97b1e38f6c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age City  Age_mean  Age_median City_mode  Age_ffill  Age_bfill  \\\n",
      "0  25.0   NY      25.0        25.0        NY       25.0       25.0   \n",
      "1  30.0   LA      30.0        30.0        LA       30.0       30.0   \n",
      "2   NaN  NaN      32.5        32.5        LA       30.0       35.0   \n",
      "3  35.0   NY      35.0        35.0        NY       35.0       35.0   \n",
      "4  40.0   LA      40.0        40.0        LA       40.0       40.0   \n",
      "\n",
      "   Age_interp  Age_random  \n",
      "0        25.0        25.0  \n",
      "1        30.0        30.0  \n",
      "2        32.5        35.0  \n",
      "3        35.0        35.0  \n",
      "4        40.0        40.0  \n"
     ]
    }
   ],
   "source": [
    "# 7. Random Sampling Imputation\n",
    "# Replace missing values with random samples from the observed data.\n",
    "\n",
    "# Random Sampling Imputation\n",
    "df['Age_random'] = df['Age'].apply(lambda x: np.random.choice(df['Age'].dropna()) if pd.isnull(x) else x)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3967d0-be50-48db-b230-e2a4d964b3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
